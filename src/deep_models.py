# -*- coding: utf-8 -*-
"""deep_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18FkBWAaZwyAciNKADMzB8yeBNBBiJd0w
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder,LabelEncoder
from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler
from sklearn.model_selection import train_test_split 
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay
from sklearn.metrics import classification_report
import time
from sklearn import metrics
import pickle
from beautifultable import BeautifulTable

import os
import seaborn as sns

import torch
from functions import plot_top_n,my_plot_precision_recall_curve, confusion_matrix_plot,download_drive

import deep_classes
from deep_functions import compute_train,make_train_step,compute_test,make_test_step,plot_top_n_deepmodels





def deep_model(dataset_name,df,name_target,n,EPOCH):

    X_asli,Y_asli = df.loc[:, df.columns!= name_target], df[name_target]

    X_asli = X_asli.to_numpy(copy=True)
    Y_asli = Y_asli.to_numpy(copy=True)

    X_train_asli, X_test_asli, y_train_asli, y_test_asli = train_test_split(X_asli, Y_asli, test_size=0.3, random_state=120)


    print('*******************************************************Deepant model')

    # MODEL_SELECTED Possible Values ['deepant', 'lstmae']
    MODEL_SELECTED = 'deepant' 
    MODEL_SELECTED_1  = 'deepant'
    #DATASETNAME = dataset_name
    LOOKBACK_SIZE = df.shape[1]
    #EPOCH = 5
    shape = df.shape[1]
    PATH = f'/content/torch_model_{MODEL_SELECTED}.pt'
    # PATH_1 = f'/content/torch_model_{MODEL_SELECTED}.pt'
    # PATH_2 = f'/content/torch_model_{MODEL_SELECTED}.pt'

    #*****************************************

    _data_ = df.to_numpy(copy=True)
    X = np.zeros(shape=(df.shape[0],LOOKBACK_SIZE,df.shape[1]))
    Y = np.zeros(shape=(df.shape[0],df.shape[1]))
    for i in range(LOOKBACK_SIZE-1, df.shape[0]-1):
        #timesteps.append(df.index[i])
        Y[i-LOOKBACK_SIZE+1] = _data_[i+1]
        for j in range(i-LOOKBACK_SIZE+1, i+1):
            X[i-LOOKBACK_SIZE+1][LOOKBACK_SIZE-1-i+j] = _data_[j]

    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=120)
    #*************************

    #create a dataframe
    df_all = pd.DataFrame(columns =["method",'TP', 'FP','TN','FN','Accuracy', 'Precision', 'Recall', 'F1_score','Training Time(s)'])
    index = df_all.index
    index.name = dataset_name

    numb = len(df_all)+1

    #******************************

    loss_train_1,train_time_deepant,loss_train_deepant = compute_train(X_train,y_train,shape,EPOCH,MODEL_SELECTED,PATH,dataset_name)
    #print('loss_tarin_1',loss_train_1)

    #******************
    #DeepAnT
    #LSTMAE
    model_test = deep_classes.DeepAnT(shape,shape,dataset_name)
    model_test.load_state_dict(torch.load(PATH))
    loss_test_1,loss_test_deepant = compute_test(X_test,y_test,model_test,EPOCH,MODEL_SELECTED)
    #*******************************************

    loss_total_1 = np.concatenate((loss_train_1,loss_test_1), axis = 0)
    #***************************************
    for i in range(0,len(loss_test_1)):
        if loss_test_1[i] > 0.5:
          loss_test_1[i]=1
        else:
          loss_test_1[i]=0
    #***************************************     

    predictions_1 = loss_test_1
    #predictions = [round(value) for value in predictions]
    accuracy = accuracy_score(y_test_asli, predictions_1)
    accuracy_1 = accuracy * 100.0
    #print('accuracy_1: ',accuracy_1)


    # # calculate prediction,recall, f1-score
    from sklearn.metrics import f1_score,recall_score,precision_score
    precision = precision_score(y_test_asli, predictions_1, average='weighted', labels=np.unique(predictions_1))
    recall = recall_score(y_test_asli, predictions_1, average='weighted', labels=np.unique(predictions_1))
    f1_score = f1_score(y_test_asli, predictions_1, average='weighted', labels=np.unique(predictions_1))
    f1_score_1 = np.mean(f1_score)
    precision_1 = np.mean(precision)
    recall_1 = np.mean(recall)

    # evaluate the classification_report
    print('*****************************************classification_report')
    print(classification_report(y_test_asli, predictions_1))   

    
    # evaluate the confusion_matrix
    cf_matrix =confusion_matrix(y_test_asli, predictions_1)
    tn, fp, fn, tp = confusion_matrix(y_test_asli, predictions_1).ravel()

    # #***********************************************************confusion matrix Plot
    print('*******************************************confusion matrix Plot')

    confusion_matrix_plot(y_test_asli,predictions_1,MODEL_SELECTED,0.2,True)

    # #************************************************
    df_all.loc[numb]= [f"{MODEL_SELECTED}",tn, fp, fn, tp, accuracy_1, precision_1,recall_1,f1_score_1,train_time_deepant]
    numb = len(df_all)+1




    #************************************
    print('*******************************************************************lstmae model')

    # MODEL_SELECTED Possible Values ['deepant', 'lstmae']
    MODEL_SELECTED = "lstmae" 
    LOOKBACK_SIZE = df.shape[1]
    PATH = f'/content/torch_model_{MODEL_SELECTED}.pt'
    #EPOCH = 5
    shape = df.shape[1]

    #*******************************************************

    loss_train_2,train_time_lstmae,loss_train_lstmae = compute_train(X_train,X_train,shape,EPOCH,MODEL_SELECTED,PATH,dataset_name)

    #*********************************************
    #DeepAnT
    #LSTMAE
    model_test = deep_classes.LSTMAE(shape,shape)
    model_test.load_state_dict(torch.load(PATH))
    loss_test_2,loss_test_lstmae = compute_test(X_test,X_test,model_test,EPOCH,MODEL_SELECTED)
    #**************************************************

    loss_total_2 = np.concatenate((loss_train_2,loss_test_2), axis = 0)
    #*******************************

    for i in range(0,len(loss_test_2)):
        if loss_test_2[i] > 0.7:
          loss_test_2[i]=1
        else:
          loss_test_2[i]=0

    #***********************
    predictions_2 = loss_test_2
    #predictions = [round(value) for value in predictions]
    accuracy = accuracy_score(y_test_asli, predictions_2)
    accuracy_2 = accuracy * 100.0
    #print('accuracy_2:',accuracy_2)


    # # calculate prediction,recall, f1-score
    from sklearn.metrics import f1_score,recall_score,precision_score
    precision = precision_score(y_test_asli, predictions_2, average='weighted', labels=np.unique(predictions_2))
    recall = recall_score(y_test_asli, predictions_2, average='weighted', labels=np.unique(predictions_2))
    f1_score = f1_score(y_test_asli, predictions_2, average='weighted', labels=np.unique(predictions_2))
    f1_score_2 = np.mean(f1_score)
    precision_2 = np.mean(precision)
    recall_2 = np.mean(recall)

    # evaluate the classification_report
    print('*****************************************classification_report')
    print(classification_report(y_test_asli, predictions_2))   


    # evaluate the confusion_matrix
    cf_matrix =confusion_matrix(y_test_asli, predictions_2)
    tn, fp, fn, tp = confusion_matrix(y_test_asli, predictions_2).ravel()

    # #*******************************************confusion matrix Plot

    confusion_matrix_plot(y_test_asli,predictions_2,MODEL_SELECTED,0.2,True)

    # #************************************************

    df_all.loc[numb]= [f"{MODEL_SELECTED}",tn, fp, fn, tp, accuracy_2, precision_2,recall_2,f1_score_2,train_time_lstmae]
    numb = len(df_all)+1


    #************************************loss plot deepant
    # summarize history for loss
    plt.plot(loss_train_deepant)
    plt.plot(loss_test_deepant)
    plt.title('deepant model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    #plt.ylim(.0, .50)
    plt.legend(['train', 'test'],bbox_to_anchor=(1.04,1), loc='upper left')
    plt.show()

    #************************************loss plot lstmae
    # summarize history for loss
    plt.plot(loss_train_lstmae)
    plt.plot(loss_test_lstmae)
    plt.title('lstmae model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'],bbox_to_anchor=(1.04,1), loc='upper left')
    plt.show()


    #*************************************Top N data plot

    plot_top_n_deepmodels(df,n,name_target,loss_total_1,loss_total_2)


    #************************************************ Plot_precision_recall_curve

    from sklearn.metrics import precision_recall_curve
    from sklearn.metrics import plot_precision_recall_curve

    disp_1 = my_plot_precision_recall_curve(y_test_asli, predictions_1,MODEL_SELECTED_1)
    average_precision_1 = metrics.average_precision_score(y_test_asli, predictions_1)

    disp_2 = my_plot_precision_recall_curve(y_test_asli, predictions_2,MODEL_SELECTED)
    average_precision_2 = metrics.average_precision_score(y_test_asli, predictions_2)

    plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
    plt.show()

    #*************************************************ROC PLOT

    plt.figure(0).clf()

    fpr, tpr, thresh = metrics.roc_curve(y_test_asli, predictions_1)
    auc = metrics.roc_auc_score(y_test_asli, predictions_1)
    plt.plot(fpr,tpr,label="Deepant, auc="+str("{:.3%}".format(auc)))

    fpr, tpr, thresh = metrics.roc_curve(y_test_asli, predictions_2)
    auc = metrics.roc_auc_score(y_test_asli, predictions_2)
    plt.plot(fpr,tpr,label="lstmae, auc="+str("{:.3%}".format(auc)))

    plt.title('ROC-Curve')
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    #plt.legend(loc=0)
    plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
    plt.show()


    return df_all




