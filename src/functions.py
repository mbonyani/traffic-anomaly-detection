# -*- coding: utf-8 -*-
"""functions_11_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12vY8t-CromfWrmgkr7qsit8s708buHY3
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split 
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

import matplotlib.pyplot as plt
from sklearn import metrics

import xbosmodel

import os
import kaggle
import seaborn as sns
import time

from termcolor import colored


def download_drive(dataset_kaggle_path,dataset_dir):
    """
    Downloads dataset from Kaggle and loads it in dataset_dir.
    """
    if not os.path.exists(dataset_dir):
        kaggle.api.authenticate()
        kaggle.api.dataset_download_files(dataset=dataset_kaggle_path, path=dataset_dir, unzip=True)
        print('Download completed.')
    else:
        print('dataset already exists.')
    
    return True


def confusion_matrix_plot(y_test,y_test_pred,model_name,contamination,percentage_values):
    #name = ["Abnormal","Normal"]     
    #percentage_values = True #@param {type:"boolean"}

    tp, fn, fp, tn = confusion_matrix(y_test, y_test_pred).ravel()

    fig, ax = plt.subplots(figsize=(7, 10))
    fig.tight_layout()

    ax = plt.subplot(1, 2, 1)
    sns.heatmap([[.1, .3], 
                  [.4, .2]], 
                annot=np.array([[f'TP\n{tn}', f'FN\n{fp}'],
                                [f'FP\n{fn}', f'TN\n{tp}']]),
                                annot_kws={"size": 14},
                                cbar=False,
                                square=True,
                                linewidths=.5,
                                xticklabels=["1", "0"],
                                yticklabels=["1", "0"], 
                                fmt = '', ax=ax)
    ax.set_title("Legend for \nconfusion matrix")
    ax.tick_params(axis='x', rotation=45)
    ax.tick_params(axis='y', rotation=0)

    ax = plt.subplot(1, 2, 2)
    cm = confusion_matrix(y_test, y_test_pred)
    cm  = np.fliplr(cm)
    cm = np.flipud(cm)
    if percentage_values:
      #cm = cm.T
      cm = np.round(cm / cm.sum(axis=1)[:, np.newaxis], decimals=2)
    cmd = ConfusionMatrixDisplay(cm, display_labels=["Abnormal","Normal"])
    if percentage_values:
      cmd.plot(ax=ax, xticks_rotation=45, cmap=plt.cm.Blues, values_format=".2%")
    else:
      cmd.plot(ax=ax, xticks_rotation=45, cmap=plt.cm.Blues, values_format="")
    cmd.ax_.set_title(f"confusion matrix - {model_name}")
    cmd.im_.colorbar.remove()
    cmd.ax_.set_xlabel('')
    cmd.ax_.set_ylabel('')

    fig.text(0, 0.5, "True Label/ Ground Truth/ Actual class", rotation=90, va='center')
    fig.text(0.3, 0.3, 'Estimated/Predicted Label/ Predicted class', ha='left')
    plt.subplots_adjust(wspace=0.9)
    plt.suptitle(f"Confusion Matrix - {model_name} - Testset (contamination = {contamination})", y=0.7)
    plt.show()

    #tn, fp, fn, tp = confusion_matrix(y_test_sf, y_pred_test_).ravel()
    print('TN: {}\t     FP: {}\t FN: {}\t TP: {}\t'.format(tn, fp, fn, tp))
    print('TP+FN: {}\t'.format(tp+fn))
    print('TN+FP: {}\t'.format(tn+fp))
    
    print('Normal Instances Detected (True Negatives): ', cm[0][0])
    print('Normal Instances Incorrectly Detected (False Positives): ', cm[0][1])
    print('Abnormal Instances Missed (False Negatives): ', cm[1][0])
    print('Abnormal Instances Detected (True Positives): ', cm[1][1])
    print('Anomalies/outliers: ', np.sum(cm[1]))


def my_plot_precision_recall_curve(ytest,ypred,name):
  
  from sklearn.metrics import precision_recall_curve
  from sklearn.metrics import plot_precision_recall_curve
  precision, recall, _ = precision_recall_curve(ytest, ypred)
  average_precision = metrics.average_precision_score(ytest, ypred)
      
  viz = metrics.PrecisionRecallDisplay(
          precision=precision,
          recall=recall,
          average_precision=average_precision,
          estimator_name=name,
          )

  return viz.plot(ax= plt.gca(), name=name)


def pie_chart(dataset_name,counts_elements,unique_elements):  
    import matplotlib.pyplot as plt
    # Pie chart, where the slices will be ordered and plotted counter-clockwise:
    #labels = 'normal', 'outliers'
    #sizes = [subtract, sdf_null_]
    explode = (0.3, 0)  # only "explode" the 2nd slice (i.e. 'with param')

    fig1, ax1 = plt.subplots()
    ax1.pie(counts_elements, explode=explode, labels=unique_elements, autopct='%2.2f%%',
            shadow=True, startangle=180,textprops= {'fontsize':18})
    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    ax1.set_title(dataset_name)
    plt.show()


def plot_top_n(df,n,name_target,contamination,number_of_unique,list_of_models):

    
    from pyod.models.hbos import HBOS
    from pyod.models.knn import KNN 
    from pyod.models.iforest import IForest
    from pyod.models.lof import LOF
    from sklearn.neighbors import KNeighborsClassifier
    from xgboost import XGBClassifier
    #from somlearn import SOM
    from sklearn_som.som import SOM
    from sklearn.neighbors import LocalOutlierFactor
    from sklearn.svm import OneClassSVM
    from pyod.models.ocsvm import OCSVM
    from sklearn.linear_model import SGDOneClassSVM
    from pyod.models.mcd import MCD

    from sklearn import metrics

    orig = df.copy()
    results = []

    #*************************************
    if 'HBOS_pyod' in list_of_models:
      # train HBOS detector
      clf_name = 'HBOS_pyod'
      clf = HBOS(contamination=contamination)
      clf.fit(orig)
      hbos_result = clf.decision_function(orig)
      #results.append(hbos_result)

      #hbos_result = results[0]
      hbos_orig = orig.copy()
      #hbos_orig[titles[i]] = hbos_result
      hbos_orig['HBOS_pyod'] = hbos_result
      hbos_topN_data = hbos_orig.sort_values(by=['HBOS_pyod'],ascending=False)[:n]

    #*********************************
    if 'KNN_pyod' in list_of_models:
      # train KNN detector
      clf_name = 'KNN_pyod'
      clf = KNN(contamination=contamination)
      clf.fit(orig)
      knn_result = clf.decision_function(orig)
      #results.append(knn_result)

      #knn_result = results[1]
      knn_orig = orig.copy()
      knn_orig['KNN_pyod'] = knn_result
      knn_topN_data = knn_orig.sort_values(by=['KNN_pyod'],ascending=False)[:n]

    #*************************************
    if 'IForest_pyod' in list_of_models:
      # train IForest detector
      clf_name = 'IForest_pyod'
      clf = IForest(contamination=contamination)
      clf.fit(orig)
      iforest_result = clf.decision_function(orig)
      #results.append(iforest_result)

      #iforest_result = results[2]
      iforest_orig = orig.copy()
      iforest_orig['IForest_pyod'] = iforest_result
      iforest_topN_data = iforest_orig.sort_values(by=['IForest_pyod'],ascending=False)[:n]

    #*********************************************
    if 'LOF_pyod' in list_of_models:


      # train LOF detector
      clf_name = 'LOF_pyod'
      clf = LOF(contamination=contamination)
      clf.fit(orig)
      lof_result = -clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      lof_orig = orig.copy()
      lof_orig['LOF_pyod'] = lof_result
      lof_topN_data = lof_orig.sort_values(by=['LOF_pyod'],ascending=False)[:n]

    #*****************************************
    if 'XBOS' in list_of_models:
      # train XBOS detector

      if number_of_unique != None:

        df_2 = df.copy()

        #remove columns with constant numbers or those columns with unique numbers of < number_of_unique
        cols = df_2.columns
        for i in range(len(cols)):
          if cols[i] != name_target:
            m = df_2[cols[i]].value_counts()
            m = np.array(m)
            if len(m) < number_of_unique:
              #print(f'len cols {i}:',len(m), 'from plot droped')
              #print('drope')
              column_name = cols[i]
              df_2=df_2.drop(columns= column_name)

        X, y = df_2.loc[:, df_2.columns!= name_target],df_2[name_target]
        X_2 = X
        y_2 = y

      else:

        X, y = orig.loc[:, orig.columns!= name_target],orig[name_target]

      clf = xbosmodel.XBOS(n_clusters=15,max_iter=1)
      xbos_result = clf.fit_predict(X)
      #results.append(xbos_result)
      
      #xbos_result = results[4]
      xbos_orig = orig.copy()
      xbos_orig['XBOS'] = xbos_result
      xbos_topN_data = xbos_orig.sort_values(by=['XBOS'],ascending=True)[:n]
    #****************************************
    if 'KNN_sklearn' in list_of_models:
      # train KNN from sklearn
      X, y = orig.loc[:, orig.columns!= name_target], orig[name_target]

      neigh = KNeighborsClassifier(n_neighbors=3)
      # start = time.time()
      neigh.fit(X,y)
      # get the prediction on the test data
      #knn_sklearn_result = neigh.predict(X)
      knn_sklearn_result = neigh.predict_proba(X)[:,1]

      #results.append(knn_sklearn_result)

      #knn_sklearn_result = results[5]
      knn_sklearn_orig = orig.copy()
      knn_sklearn_orig['knn_sklearn'] = knn_sklearn_result
      knn_sklearn_topN_data = knn_sklearn_orig.sort_values(by=['knn_sklearn'],ascending=False)[:n]
    #*****************************************XGB
    if 'XGB' in list_of_models:
      # train XGB detector
      if number_of_unique != None:
        X = X_2
        y = y_2      
        #X, y = df_2.loc[:, df_2.columns!= name_target],df_2[name_target]

      else:
        X, y = orig.loc[:, orig.columns!= name_target],orig[name_target]

      model = XGBClassifier(learning_rate = 0.05, n_estimators=300, max_depth=5)
      model.fit(X, y)
      # make predictions for test set
      xgb_result = model.predict(X)
      #results.append(xgb_result)
      #xgb_result = results[6]
      xgb_orig = orig.copy()
      xgb_orig['XGB'] = xgb_result
      xgb_topN_data = xgb_orig.sort_values(by=['XGB'],ascending=False)[:n]

    #****************************************    

    if 'SOM' in list_of_models:

      # train HBOS detector
      clf_name = 'SOM'
      num_row , num_column = orig.shape

      orig2 = orig.copy()
      orig2 = np.array(orig2)

      #clf = SOM(n_columns=num_column, n_rows=num_row, random_state=1)
      clf = SOM(m=2, n=1, dim=num_column)
      #clf.fit(orig)
      som_result = clf.fit_predict(orig2)

      som_orig = orig.copy()
      som_orig['SOM'] = som_result
      som_topN_data = som_orig.sort_values(by=['SOM'],ascending=True)[:n]
    #******************************************

    if 'LOF_sklearn' in list_of_models:

      # train LOF detector
      clf_name = 'LOF_sklearn'
      clf = LocalOutlierFactor(n_neighbors=3,novelty=True, contamination=contamination)
      clf.fit(orig)
      lof_sklearn_result = -clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      lof_sklearn_orig = orig.copy()
      lof_sklearn_orig['LOF_sklearn'] = lof_sklearn_result
      lof_sklearn_topN_data = lof_sklearn_orig.sort_values(by=['LOF_sklearn'],ascending=False)[:n]
    #********************************************

    if 'OneClassSVM' in list_of_models:
      # train LOF detector
      clf_name = 'OneClassSVM'
      # train OneClassSVM detector
      clf = OneClassSVM(gamma='auto')
      clf.fit(orig)
      OneClassSVM_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      OneClassSVM_orig = orig.copy()
      OneClassSVM_orig['OneClassSVM'] = OneClassSVM_result
      OneClassSVM_topN_data = OneClassSVM_orig.sort_values(by=['OneClassSVM'],ascending=False)[:n]
#*********************************************************

    if 'OCSVM_pyod' in list_of_models:
      # train LOF detector
      clf_name = 'OCSVM_pyod'
      # train OneClassSVM detector
      clf = OCSVM(gamma='auto')
      clf.fit(orig)
      OCSVM_pyod_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      OCSVM_pyod_orig = orig.copy()
      OCSVM_pyod_orig['OCSVM_pyod'] = OCSVM_pyod_result
      OCSVM_pyod_topN_data = OCSVM_pyod_orig.sort_values(by=['OCSVM_pyod'],ascending=False)[:n]

#**************************************************

    if 'SGDOneClassSVM' in list_of_models:
      # train LOF detector
      clf_name = 'SGDOneClassSVM'
      # train OneClassSVM detector
      clf = SGDOneClassSVM()
      clf.fit(orig)
      SGDOneClassSVM_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      SGDOneClassSVM_orig = orig.copy()
      SGDOneClassSVM_orig['SGDOneClassSVM'] = SGDOneClassSVM_result
      SGDOneClassSVM_topN_data = SGDOneClassSVM_orig.sort_values(by=['SGDOneClassSVM'],ascending=False)[:n]

#**************************************************

    if 'MCD_pyod' in list_of_models:
      # train HBOS detector
      clf_name = 'MCD_pyod'
      num_row , num_column = orig.shape
      sup_frac = float((num_row+num_column+1) /2)
      clf = MCD(contamination= contamination,support_fraction=sup_frac)

      clf.fit(orig)
      mcd_result = clf.decision_function(orig)
      #results.append(hbos_result)

      #hbos_result = results[0]
      mcd_orig = orig.copy()
      #hbos_orig[titles[i]] = hbos_result
      mcd_orig['MCD_pyod'] = mcd_result
      mcd_topN_data = mcd_orig.sort_values(by=['MCD_pyod'],ascending=False)[:n]


#***********************************************

    from matplotlib import pyplot as plt
    if 'HBOS_pyod' in list_of_models:
      plt.scatter(range(n),hbos_topN_data[name_target].cumsum(),marker='1',label='HBOS_pyod')

    if 'KNN_pyod' in list_of_models:
      plt.scatter(range(n),knn_topN_data[name_target].cumsum(),marker='1',label='KNN_pyod')

    if 'IForest_pyod' in list_of_models:
      plt.scatter(range(n),iforest_topN_data[name_target].cumsum(),marker='1',label='IForest_pyod')

    if 'LOF_pyod' in list_of_models:
      plt.scatter(range(n),lof_topN_data[name_target].cumsum(),marker='1',label='LOF_pyod')

    if 'XBOS' in list_of_models:
      plt.scatter(range(n),xbos_topN_data[name_target].cumsum(),marker='1',label='XBOS')

    if 'KNN_sklearn' in list_of_models:
      plt.scatter(range(n),knn_sklearn_topN_data[name_target].cumsum(),marker='1',label='knn_sklearn')  

    if 'XGB' in list_of_models:
      plt.scatter(range(n),xgb_topN_data[name_target].cumsum(),marker='1',label='XGB')

    if 'SOM' in list_of_models:
      plt.scatter(range(n),som_topN_data[name_target].cumsum(),marker='1',label='SOM')

    if 'LOF_sklearn' in list_of_models:
      plt.scatter(range(n),lof_sklearn_topN_data[name_target].cumsum(),marker='1',label='LOF_sklearn')

    if 'OneClassSVM' in list_of_models:
      plt.scatter(range(n),OneClassSVM_topN_data[name_target].cumsum(),marker='1',label='OneClassSVM')        

    if 'OCSVM_pyod' in list_of_models:
      plt.scatter(range(n),OCSVM_pyod_topN_data[name_target].cumsum(),marker='1',label='OCSVM_pyod')      

    if 'SGDOneClassSVM' in list_of_models:
      plt.scatter(range(n),SGDOneClassSVM_topN_data[name_target].cumsum(),marker='1',label='SGDOneClassSVM')          

    if 'MCD_pyod' in list_of_models:
      plt.scatter(range(n),mcd_topN_data[name_target].cumsum(),marker='1',label='MCD_pyod')


    plt.xlabel('Top N data')
    plt.ylabel('Anomalies found')
    plt.title('How many anomalies can we find in the top N data ( N=1... 1000 )? \n AUC-ish score') 
    plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
    plt.show()
    


def auc_plot(df,name_target,contamination,number_of_unique,list_of_models,k):
    
    from pyod.models.hbos import HBOS
    from pyod.models.knn import KNN 
    from pyod.models.iforest import IForest
    from pyod.models.lof import LOF
    from sklearn.neighbors import KNeighborsClassifier
    from xgboost import XGBClassifier
    #from somlearn import SOM
    from sklearn_som.som import SOM
    from sklearn.neighbors import LocalOutlierFactor
    from sklearn.svm import OneClassSVM
    

    from sklearn import metrics

    orig = df.copy()
    #bins = list(range(0,k+1))

    predictions_list = []

    if contamination > 0.5:
      contamination = 0.5

    X, y = df.loc[:, df.columns!= name_target], df[name_target]
    seed = 120
    test_size = 0.3
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed,stratify=y)
    #print('X_test:',X_test.shape,'y_test:',y_test.shape)

#*************************************
    if 'HBOS_pyod' in list_of_models:
      
      predictions_1_j = []
      auc_1_j = []

      for j in range(len(k)):

        model_name_1 = 'HBOS_pyod'
        # train HBOS detector
        clf_name = 'HBOS_pyod'
        clf = HBOS(n_bins=k[j],contamination= contamination)
        #start = time.time()
        clf.fit(X_train)

        # get the prediction on the test data

        #y_test_pred_1 = clf.predict(X_test)  # outlier labels (0 or 1)
        y_test_pred_1 = clf.decision_function(X_test)  # outlier scores

        #predictions = [round(value) for value in y_test_pred_1]
        predictions = y_test_pred_1
        # for i in range(0,len(predictions)):
        #   if predictions[i] > 0.5:
        #     predictions[i]=1
        #   else:
        #     predictions[i]=0

        predictions_1_j.append(predictions) 

        # #AUC score
        auc_1 = metrics.roc_auc_score(y_test, predictions)             
        auc_1_j.append(auc_1)
        #print('auc_1_j', auc_1_j)

#***********************************************
    if 'KNN_pyod' in list_of_models:

      from pyod.models.knn import KNN 

      predictions_2_j = []
      auc_2_j = []

      for j in range(len(k)):

        model_name_2 = 'KNN_pyod'
        # train kNN detector
        clf_name = 'KNN_pyod'
        clf = KNN(contamination= contamination,n_neighbors=k[j])

        clf.fit(X_train)

        # get the prediction on the test data
        #y_test_pred_2 = clf.predict(X_test)  # outlier labels (0 or 1)
        y_test_pred_2 = clf.decision_function(X_test)  # outlier scores

        #predictions = [round(value) for value in y_test_pred_2]
        predictions = y_test_pred_2
        # for i in range(0,len(predictions)):
        #   if predictions[i] > 0.5:
        #     predictions[i]=1
        #   else:
        #     predictions[i]=0

        predictions_2_j.append(predictions)
        
        # #AUC score
        auc_2 = metrics.roc_auc_score(y_test, predictions)     
        auc_2_j.append(auc_2)
        #print('auc_2_j', auc_2_j)

#****************************************************************LOF
    if 'LOF_pyod' in list_of_models:

      #print('******************************************************************LOF_pyod')
      from pyod.models.lof import LOF
      import time


      predictions_4_j = []
      auc_4_j = []

      for j in range(len(k)):

        model_name_4 = 'LOF_pyod'

        # train LOF detector
        clf_name = 'LOF_pyod'
        clf = LOF(n_neighbors=k[j],contamination= contamination)
        #start = time.time()
        clf.fit(X_train)

        # get the prediction on the test data
        #y_test_pred_4 = clf.predict(X_test)  # outlier labels (0 or 1)
        y_test_pred_4 = -clf.decision_function(X_test)  # outlier scores
        #****************************************
        #predictions = [round(value) for value in y_test_pred_4]
        predictions = y_test_pred_4


        predictions_4_j.append(predictions)

        # #AUC score
        auc_4 = metrics.roc_auc_score(y_test, predictions)     
        auc_4_j.append(auc_4)
        #print('auc_4_j', auc_4_j)

#****************************************************************XBOS
    if 'XBOS' in list_of_models:

      #print('******************************************************************XBOS')
      import time
      #df_2_exist = False

      if number_of_unique != None:
        df_2 = df.copy()

        #remove columns with constant numbers or those columns with unique numbers of < number_of_unique
        cols = df_2.columns
        for i in range(len(cols)):
          if cols[i] != name_target:
            m = df_2[cols[i]].value_counts()
            m = np.array(m)
            if len(m) < number_of_unique:
              print(f'len cols {i}:',len(m), 'droped')
              #print('drope')
              column_name = cols[i]
              df_2=df_2.drop(columns= column_name)

        X_2, y_2= df_2.loc[:, df_2.columns!= name_target], df_2[name_target]
        X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.3, random_state=120,stratify=y_2)

        predictions_5_j = []
        auc_5_j = []

        for j in range(len(k)):
          model_name_5 = 'XBOS'
          #create XBOS model
          clf = xbosmodel.XBOS(n_clusters=k[j],max_iter=1)
          #start = time.time()
          # train XBOS model
          clf.fit(X_train_2)
          
          #predict model
          #y_test_pred_5 = clf.predict(X_test_2)
          y_test_pred_5 = clf.fit_predict(X_test_2)
          #predictions = [round(value) for value in y_test_pred_5]

          predictions = y_test_pred_5

          # for i in range(0,len(predictions)):
          #   if predictions[i] > 0.5:
          #     predictions[i]=1
          #   else:
          #     predictions[i]=0

          predictions_5_j.append(predictions)

          # #AUC score
          auc_5 = metrics.roc_auc_score(y_test, predictions)     
          auc_5_j.append(auc_5)

      else:
        predictions_5_j = []
        auc_5_j = []

        for j in range(len(k)):

          model_name_5 = 'XBOS'
          #create XBOS model
          clf = xbosmodel.XBOS(n_clusters=k[j],max_iter=1)
          start = time.time()
          # train XBOS model
          clf.fit(X_train)

          #predict model
          #y_test_pred_5 = clf.predict(X_test)
          y_test_pred_5 = clf.fit_predict(X_test)
          #predictions = [round(value) for value in y_test_pred_5]
          predictions = y_test_pred_5
          # for i in range(0,len(predictions)):
          #   if predictions[i] > 0.5:
          #     predictions[i]=1
          #   else:
          #     predictions[i]=0

          predictions_5_j.append(predictions)

          # #AUC score
          auc_5 = metrics.roc_auc_score(y_test, predictions)     
          auc_5_j.append(auc_5)
          #print('auc_5_j', auc_5_j)

#**********************************************************************KNN_sklearn
    if 'KNN_sklearn' in list_of_models:

      #print('*****************************************************************KNN from sklearn lib')
      
      from sklearn.neighbors import KNeighborsClassifier
      import time

      predictions_6_j = []
      auc_6_j = []

      for j in range(len(k)):
        model_name_6 = 'KNN_sklearn'
        # train knn detector
        neigh = KNeighborsClassifier(n_neighbors=k[j])
        neigh.fit(X_train,y_train)

        # get the prediction on the test data
        #y_test_pred_6 = neigh.predict(X_test)
        y_test_pred_6 = neigh.predict_proba(X_test)[:,1]
        #*****************************************************
        #predictions = [round(value) for value in y_test_pred_6]

        predictions = y_test_pred_6


        predictions_6_j.append(predictions)
        
        # #AUC score
        auc_6 = metrics.roc_auc_score(y_test, predictions)     
        auc_6_j.append(auc_6)
        #print('auc_6_j', auc_6_j)

#**********************************************************
    if 'LOF_sklearn' in list_of_models:

      #print('*****************************************************************LOF from sklearn lib')
      
      from sklearn.neighbors import LocalOutlierFactor
      import time


      predictions_9_j = []
      auc_9_j = []

      for j in range(len(k)):
        model_name_9 = 'LOF_sklearn'
        # train knn detector
        neigh = LocalOutlierFactor(n_neighbors=k[j],novelty=True, contamination=contamination)
        start = time.time()
        neigh.fit(X_train)

        # get the prediction on the test data
        #y_test_pred_9 = neigh.predict(X_test)
        y_test_pred_9 = -neigh.decision_function(X_test)
        

        #*****************************************************
        #predictions = [round(value) for value in y_test_pred_9]
        predictions = y_test_pred_9
        # for i in range(0,len(predictions)):
        #   if predictions[i] > 0.5:
        #     predictions[i]=1
        #   else:
        #     predictions[i]=0

        predictions_9_j.append(predictions)

        # #AUC score
        auc_9 = metrics.roc_auc_score(y_test, predictions)     
        auc_9_j.append(auc_9)

    #print(auc_1_j)

    if 'HBOS_pyod' in list_of_models:
      plt.plot(k,auc_1_j,marker='.',linestyle = ':',label="HBOS_pyod")

    if 'KNN_pyod' in list_of_models:
      plt.plot(k,auc_2_j,marker='o',linestyle = '-',label="KNN_pyod")

    if 'LOF_pyod' in list_of_models:
      plt.plot(k,auc_4_j,marker='>',linestyle = '-.',label="LOF_pyod")

    if 'XBOS' in list_of_models:
      plt.plot(k,auc_5_j,marker='<',linestyle = '--',label="XBOS")

    if 'KNN_sklearn' in list_of_models:
      plt.plot(k,auc_6_j,marker='s',linestyle = 'dotted',label="KNN_sklearn")

    if 'LOF_sklearn' in list_of_models:
      plt.plot(k,auc_9_j,marker='p',linestyle = 'solid',label="LOF_sklearn")      

    plt.title('ROC-Curve')
    plt.ylabel('AUC')
    plt.xlabel('K')
    #plt.axis([0, 15, 0., 1.0])
    #plt.xlim(k)
    plt.ylim([0.0, 1.0])
    #plt.legend(loc=0)
    plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
    plt.show()



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split 
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

import matplotlib.pyplot as plt
from sklearn import metrics

import xbosmodel

import os
import kaggle
import seaborn as sns
import time

from termcolor import colored




def download_drive(dataset_kaggle_path,dataset_dir):
    """
    Downloads dataset from Kaggle and loads it in dataset_dir.
    """
    if not os.path.exists(dataset_dir):
        kaggle.api.authenticate()
        kaggle.api.dataset_download_files(dataset=dataset_kaggle_path, path=dataset_dir, unzip=True)
        print('Download completed.')
    else:
        print('dataset already exists.')
    
    return True


def confusion_matrix_plot(y_test,y_test_pred,model_name,contamination,percentage_values):
    #name = ["Abnormal","Normal"]     
    #percentage_values = True #@param {type:"boolean"}

    tp, fn, fp, tn = confusion_matrix(y_test, y_test_pred).ravel()

    fig, ax = plt.subplots(figsize=(7, 10))
    fig.tight_layout()

    ax = plt.subplot(1, 2, 1)
    sns.heatmap([[.1, .3], 
                  [.4, .2]], 
                annot=np.array([[f'TP\n{tn}', f'FN\n{fp}'],
                                [f'FP\n{fn}', f'TN\n{tp}']]),
                                annot_kws={"size": 14},
                                cbar=False,
                                square=True,
                                linewidths=.5,
                                xticklabels=["1", "0"],
                                yticklabels=["1", "0"], 
                                fmt = '', ax=ax)
    ax.set_title("Legend for \nconfusion matrix")
    ax.tick_params(axis='x', rotation=45)
    ax.tick_params(axis='y', rotation=0)

    ax = plt.subplot(1, 2, 2)
    cm = confusion_matrix(y_test, y_test_pred)
    cm  = np.fliplr(cm)
    cm = np.flipud(cm)
    if percentage_values:
      #cm = cm.T
      cm = np.round(cm / cm.sum(axis=1)[:, np.newaxis], decimals=2)
    cmd = ConfusionMatrixDisplay(cm, display_labels=["Abnormal","Normal"])
    if percentage_values:
      cmd.plot(ax=ax, xticks_rotation=45, cmap=plt.cm.Blues, values_format=".2%")
    else:
      cmd.plot(ax=ax, xticks_rotation=45, cmap=plt.cm.Blues, values_format="")
    cmd.ax_.set_title(f"confusion matrix - {model_name}")
    cmd.im_.colorbar.remove()
    cmd.ax_.set_xlabel('')
    cmd.ax_.set_ylabel('')

    fig.text(0, 0.5, "True Label/ Ground Truth/ Actual class", rotation=90, va='center')
    fig.text(0.3, 0.3, 'Estimated/Predicted Label/ Predicted class', ha='left')
    plt.subplots_adjust(wspace=0.9)
    plt.suptitle(f"Confusion Matrix - {model_name} - Testset (contamination = {contamination})", y=0.7)
    plt.show()

    #tn, fp, fn, tp = confusion_matrix(y_test_sf, y_pred_test_).ravel()
    print('TN: {}\t     FP: {}\t FN: {}\t TP: {}\t'.format(tn, fp, fn, tp))
    print('TP+FN: {}\t'.format(tp+fn))
    print('TN+FP: {}\t'.format(tn+fp))
    
    print('Normal Instances Detected (True Negatives): ', cm[0][0])
    print('Normal Instances Incorrectly Detected (False Positives): ', cm[0][1])
    print('Abnormal Instances Missed (False Negatives): ', cm[1][0])
    print('Abnormal Instances Detected (True Positives): ', cm[1][1])
    print('Anomalies/outliers: ', np.sum(cm[1]))


def my_plot_precision_recall_curve(ytest,ypred,name):
  
  from sklearn.metrics import precision_recall_curve
  from sklearn.metrics import plot_precision_recall_curve
  precision, recall, _ = precision_recall_curve(ytest, ypred)
  average_precision = metrics.average_precision_score(ytest, ypred)
      
  viz = metrics.PrecisionRecallDisplay(
          precision=precision,
          recall=recall,
          average_precision=average_precision,
          estimator_name=name,
          )

  return viz.plot(ax= plt.gca(), name=name)


def pie_chart(dataset_name,counts_elements,unique_elements):  
    import matplotlib.pyplot as plt
    # Pie chart, where the slices will be ordered and plotted counter-clockwise:
    #labels = 'normal', 'outliers'
    #sizes = [subtract, sdf_null_]
    explode = (0.3, 0)  # only "explode" the 2nd slice (i.e. 'with param')

    fig1, ax1 = plt.subplots()
    ax1.pie(counts_elements, explode=explode, labels=unique_elements, autopct='%2.2f%%',
            shadow=True, startangle=180,textprops= {'fontsize':18})
    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    ax1.set_title(dataset_name)
    plt.show()


def plot_top_n(df,n,name_target,contamination,number_of_unique,list_of_models):

    
    from pyod.models.hbos import HBOS
    from pyod.models.knn import KNN 
    from pyod.models.iforest import IForest
    from pyod.models.lof import LOF
    from sklearn.neighbors import KNeighborsClassifier
    from xgboost import XGBClassifier
    #from somlearn import SOM
    from sklearn_som.som import SOM
    from sklearn.neighbors import LocalOutlierFactor
    from sklearn.svm import OneClassSVM
    from pyod.models.ocsvm import OCSVM
    from sklearn.linear_model import SGDOneClassSVM
    from pyod.models.mcd import MCD

    from sklearn import metrics

    orig = df.copy()
    results = []

    #*************************************
    if 'HBOS_pyod' in list_of_models:
      # train HBOS detector
      clf_name = 'HBOS_pyod'
      clf = HBOS(contamination=contamination)
      clf.fit(orig)
      hbos_result = clf.decision_function(orig)
      #results.append(hbos_result)

      #hbos_result = results[0]
      hbos_orig = orig.copy()
      #hbos_orig[titles[i]] = hbos_result
      hbos_orig['HBOS_pyod'] = hbos_result
      hbos_topN_data = hbos_orig.sort_values(by=['HBOS_pyod'],ascending=False)[:n]

    #*********************************
    if 'KNN_pyod' in list_of_models:
      # train KNN detector
      clf_name = 'KNN_pyod'
      clf = KNN(contamination=contamination)
      clf.fit(orig)
      knn_result = clf.decision_function(orig)
      #results.append(knn_result)

      #knn_result = results[1]
      knn_orig = orig.copy()
      knn_orig['KNN_pyod'] = knn_result
      knn_topN_data = knn_orig.sort_values(by=['KNN_pyod'],ascending=False)[:n]

    #*************************************
    if 'IForest_pyod' in list_of_models:
      # train IForest detector
      clf_name = 'IForest_pyod'
      clf = IForest(contamination=contamination)
      clf.fit(orig)
      iforest_result = clf.decision_function(orig)
      #results.append(iforest_result)

      #iforest_result = results[2]
      iforest_orig = orig.copy()
      iforest_orig['IForest_pyod'] = iforest_result
      iforest_topN_data = iforest_orig.sort_values(by=['IForest_pyod'],ascending=False)[:n]

    #*********************************************
    if 'LOF_pyod' in list_of_models:

      orig_lof = df.copy()
      #determine which class is normal (is not anomaly)
      label = np.array(orig_lof[name_target])

      # #replace labels with 0 and 1
      label = np.where(label == 0, 1 ,0)
      orig_lof[name_target]=label 

      # train LOF detector
      clf_name = 'LOF_pyod'
      clf = LOF(contamination=contamination)
      clf.fit(orig_lof)
      lof_result = clf.decision_function(orig_lof)
      #results.append(lof_result)
 
      #lof_result = results[3]
      lof_orig = orig_lof.copy()
      lof_orig['LOF_pyod'] = lof_result
      lof_topN_data = lof_orig.sort_values(by=['LOF_pyod'],ascending=False)[:n]

    #*****************************************
    if 'XBOS' in list_of_models:
      # train XBOS detector

      if number_of_unique != None:

        df_2 = df.copy()

        #remove columns with constant numbers or those columns with unique numbers of < number_of_unique
        cols = df_2.columns
        for i in range(len(cols)):
          if cols[i] != name_target:
            m = df_2[cols[i]].value_counts()
            m = np.array(m)
            if len(m) < number_of_unique:
              #print(f'len cols {i}:',len(m), 'from plot droped')
              #print('drope')
              column_name = cols[i]
              df_2=df_2.drop(columns= column_name)

        X, y = df_2.loc[:, df_2.columns!= name_target],df_2[name_target]
        X_2 = X
        y_2 = y

      else:

        X, y = orig.loc[:, orig.columns!= name_target],orig[name_target]

      clf = xbosmodel.XBOS(n_clusters=15,max_iter=1)
      xbos_result = clf.fit_predict(X)
      #results.append(xbos_result)
      
      #xbos_result = results[4]
      xbos_orig = orig.copy()
      xbos_orig['XBOS'] = xbos_result
      xbos_topN_data = xbos_orig.sort_values(by=['XBOS'],ascending=True)[:n]
    #****************************************
    if 'KNN_sklearn' in list_of_models:
      # train KNN from sklearn
      X, y = orig.loc[:, orig.columns!= name_target], orig[name_target]

      neigh = KNeighborsClassifier(n_neighbors=3)
      # start = time.time()
      neigh.fit(X,y)
      # get the prediction on the test data
      knn_sklearn_result = neigh.predict(X)
      #results.append(knn_sklearn_result)

      #knn_sklearn_result = results[5]
      knn_sklearn_orig = orig.copy()
      knn_sklearn_orig['knn_sklearn'] = knn_sklearn_result
      knn_sklearn_topN_data = knn_sklearn_orig.sort_values(by=['knn_sklearn'],ascending=False)[:n]
    #*****************************************XGB
    if 'XGB' in list_of_models:
      # train XGB detector
      if number_of_unique != None:
        X = X_2
        y = y_2      
        #X, y = df_2.loc[:, df_2.columns!= name_target],df_2[name_target]

      else:
        X, y = orig.loc[:, orig.columns!= name_target],orig[name_target]

      model = XGBClassifier(learning_rate = 0.05, n_estimators=300, max_depth=5)
      model.fit(X, y)
      # make predictions for test set
      xgb_result = model.predict(X)
      #results.append(xgb_result)
      #xgb_result = results[6]
      xgb_orig = orig.copy()
      xgb_orig['XGB'] = xgb_result
      xgb_topN_data = xgb_orig.sort_values(by=['XGB'],ascending=False)[:n]

    #****************************************    

    if 'SOM' in list_of_models:

      # train HBOS detector
      clf_name = 'SOM'
      num_row , num_column = orig.shape

      orig2 = orig.copy()
      orig2 = np.array(orig2)

      #clf = SOM(n_columns=num_column, n_rows=num_row, random_state=1)
      clf = SOM(m=2, n=1, dim=num_column)
      #clf.fit(orig)
      som_result = clf.fit_predict(orig2)

      som_orig = orig.copy()
      som_orig['SOM'] = som_result
      som_topN_data = som_orig.sort_values(by=['SOM'],ascending=True)[:n]
    #******************************************

    if 'LOF_sklearn' in list_of_models:

      orig_lof = df.copy()
      #determine which class is normal (is not anomaly)
      label = np.array(orig_lof[name_target])

      # #replace labels with 0 and 1
      label = np.where(label == 0, 1 ,0)
      orig_lof[name_target]=label 

      # train LOF detector
      clf_name = 'LOF_sklearn'
      clf = LocalOutlierFactor(n_neighbors=3,novelty=True, contamination=contamination)
      clf.fit(orig_lof)
      lof_sklearn_result = clf.decision_function(orig_lof)
      #results.append(lof_result)
 
      #lof_result = results[3]
      lof_sklearn_orig = orig_lof.copy()
      lof_sklearn_orig['LOF_sklearn'] = lof_sklearn_result
      lof_sklearn_topN_data = lof_sklearn_orig.sort_values(by=['LOF_sklearn'],ascending=False)[:n]
    #********************************************

    if 'OneClassSVM' in list_of_models:
      # train LOF detector
      clf_name = 'OneClassSVM'
      # train OneClassSVM detector
      clf = OneClassSVM(gamma='auto')
      clf.fit(orig)
      OneClassSVM_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      OneClassSVM_orig = orig.copy()
      OneClassSVM_orig['OneClassSVM'] = OneClassSVM_result
      OneClassSVM_topN_data = OneClassSVM_orig.sort_values(by=['OneClassSVM'],ascending=False)[:n]
#*********************************************************

    if 'OCSVM_pyod' in list_of_models:
      # train LOF detector
      clf_name = 'OCSVM_pyod'
      # train OneClassSVM detector
      clf = OCSVM(gamma='auto')
      clf.fit(orig)
      OCSVM_pyod_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      OCSVM_pyod_orig = orig.copy()
      OCSVM_pyod_orig['OCSVM_pyod'] = OCSVM_pyod_result
      OCSVM_pyod_topN_data = OCSVM_pyod_orig.sort_values(by=['OCSVM_pyod'],ascending=False)[:n]

#**************************************************

    if 'SGDOneClassSVM' in list_of_models:
      # train LOF detector
      clf_name = 'SGDOneClassSVM'
      # train OneClassSVM detector
      clf = SGDOneClassSVM()
      clf.fit(orig)
      SGDOneClassSVM_result = clf.decision_function(orig)
      #results.append(lof_result)
 
      #lof_result = results[3]
      SGDOneClassSVM_orig = orig.copy()
      SGDOneClassSVM_orig['SGDOneClassSVM'] = SGDOneClassSVM_result
      SGDOneClassSVM_topN_data = SGDOneClassSVM_orig.sort_values(by=['SGDOneClassSVM'],ascending=False)[:n]

#**************************************************

    if 'MCD_pyod' in list_of_models:
      # train HBOS detector
      clf_name = 'MCD_pyod'
      num_row , num_column = orig.shape
      sup_frac = float((num_row+num_column+1) /2)
      clf = MCD(contamination= contamination,support_fraction=sup_frac)

      clf.fit(orig)
      mcd_result = clf.decision_function(orig)
      #results.append(hbos_result)

      #hbos_result = results[0]
      mcd_orig = orig.copy()
      #hbos_orig[titles[i]] = hbos_result
      mcd_orig['MCD_pyod'] = mcd_result
      mcd_topN_data = mcd_orig.sort_values(by=['MCD_pyod'],ascending=False)[:n]


#***********************************************

    from matplotlib import pyplot as plt
    if 'HBOS_pyod' in list_of_models:
      plt.scatter(range(n),hbos_topN_data[name_target].cumsum(),marker='1',label='HBOS_pyod')

    if 'KNN_pyod' in list_of_models:
      plt.scatter(range(n),knn_topN_data[name_target].cumsum(),marker='1',label='KNN_pyod')

    if 'IForest_pyod' in list_of_models:
      plt.scatter(range(n),iforest_topN_data[name_target].cumsum(),marker='1',label='IForest_pyod')

    if 'LOF_pyod' in list_of_models:
      plt.scatter(range(n),lof_topN_data[name_target].cumsum(),marker='1',label='LOF_pyod')

    if 'XBOS' in list_of_models:
      plt.scatter(range(n),xbos_topN_data[name_target].cumsum(),marker='1',label='XBOS')

    if 'KNN_sklearn' in list_of_models:
      plt.scatter(range(n),knn_sklearn_topN_data[name_target].cumsum(),marker='1',label='knn_sklearn')  

    if 'XGB' in list_of_models:
      plt.scatter(range(n),xgb_topN_data[name_target].cumsum(),marker='1',label='XGB')

    if 'SOM' in list_of_models:
      plt.scatter(range(n),som_topN_data[name_target].cumsum(),marker='1',label='SOM')

    if 'LOF_sklearn' in list_of_models:
      plt.scatter(range(n),lof_sklearn_topN_data[name_target].cumsum(),marker='1',label='LOF_sklearn')

    if 'OneClassSVM' in list_of_models:
      plt.scatter(range(n),OneClassSVM_topN_data[name_target].cumsum(),marker='1',label='OneClassSVM')        

    if 'OCSVM_pyod' in list_of_models:
      plt.scatter(range(n),OCSVM_pyod_topN_data[name_target].cumsum(),marker='1',label='OCSVM_pyod')      

    if 'SGDOneClassSVM' in list_of_models:
      plt.scatter(range(n),SGDOneClassSVM_topN_data[name_target].cumsum(),marker='1',label='SGDOneClassSVM')          

    if 'MCD_pyod' in list_of_models:
      plt.scatter(range(n),mcd_topN_data[name_target].cumsum(),marker='1',label='MCD_pyod')


    plt.xlabel('Top N data')
    plt.ylabel('Anomalies found')
    plt.title('How many anomalies can we find in the top N data ( N=1... 1000 )? \n AUC-ish score') 
    plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
    plt.show()
    

